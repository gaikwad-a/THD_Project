{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871f5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Step 1: Handling Missing Values\n",
    "# Replace \"N/A\" with Pandas' NaN\n",
    "data.replace(\"N/A\", pd.NA, inplace=True)\n",
    "\n",
    "# Optionally, fill NaN values with a placeholder\n",
    "# data.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Alternatively, you could drop rows or columns with missing values\n",
    "# data.dropna(inplace=True)  # Uncomment this line if you want to drop rows with any missing values\n",
    "\n",
    "# Step 2: Standardizing Units\n",
    "# Assume that all units are already standardized in your dataset\n",
    "\n",
    "# Step 3: Data Type Conversion\n",
    "# Example: Convert Carbon_Footprint to float if it's stored as string\n",
    "# This step may not be necessary if your data is already in the correct data type\n",
    "# data['Carbon_Footprint'] = data['Carbon_Footprint'].astype(float)  # Uncomment & adjust if necessary\n",
    "\n",
    "# Step 4: Categorical Data Encoding\n",
    "# Example: Convert Energy_Efficiency to numerical values\n",
    "energy_efficiency_mapping = {'A+': 3, 'A': 2, 'A-': 1}\n",
    "data['Energy_Efficiency'] = data['Energy_Efficiency'].map(energy_efficiency_mapping)\n",
    "\n",
    "# Step 5: Checking for Duplicates\n",
    "# Remove duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the cleaned data back to a CSV file\n",
    "data.to_csv('cleaned_eco_products.csv', index=False)\n",
    "\n",
    "# Now your data is cleaned and preprocessed, and ready for further analysis or processing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e0f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned data\n",
    "data = pd.read_csv('cleaned_eco_products.csv')\n",
    "\n",
    "# Convert 'Water_Usage' to a numerical format (assuming all values are in Liters)\n",
    "# Extract the numerical part of the string, then convert to float\n",
    "data['Water_Usage'] = data['Water_Usage'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "# Now you can proceed with handling missing values\n",
    "# Imputation:\n",
    "# Numerical Imputation: Fill missing values in 'Water_Usage' with the column median\n",
    "data['Water_Usage'].fillna(data['Water_Usage'].median(), inplace=True)\n",
    "\n",
    "# Categorical Imputation: Fill missing values in 'Energy_Efficiency' with a placeholder 'Unknown'\n",
    "data['Energy_Efficiency'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Alternatively, Removal:\n",
    "# Uncomment the line below if you choose to remove the rows instead of imputation\n",
    "# data.dropna(subset=['Energy_Efficiency', 'Water_Usage'], inplace=True)\n",
    "\n",
    "# Save the updated data back to a CSV file\n",
    "data.to_csv('updated_cleaned_eco_products.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156ecf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "df = pd.read_csv('Final_data.csv')\n",
    "\n",
    "\n",
    "def label_products(row):\n",
    "    labels = []\n",
    "    \n",
    "    # Energy Efficiency Labeling\n",
    "    if row['Energy_Efficiency'] == 3.0:\n",
    "        labels.append('Highly Energy Efficient')\n",
    "    elif row['Energy_Efficiency'] == 2.0:\n",
    "        labels.append('Moderately Energy Efficient')\n",
    "    elif row['Energy_Efficiency'] == 1.0:\n",
    "        labels.append('Low Energy Efficiency')\n",
    "    elif row['Energy_Efficiency'] == 'Unknown':\n",
    "        labels.append('Energy Efficiency Unknown')\n",
    "    \n",
    "    # Material based labeling\n",
    "    if row['Material'] in ['Bamboo', 'Recycled']:\n",
    "        labels.append('Sustainably Sourced')\n",
    "    \n",
    "    # Recyclable\n",
    "    if row['Recyclable'] == 'Yes':\n",
    "        labels.append('Recyclable')\n",
    "    \n",
    "    # Water usage\n",
    "    if row['Water_Usage'] < 50.0:  # assuming water usage is a string like \"30.0 Liters\"\n",
    "        labels.append('Water Efficient')\n",
    "    \n",
    "    # Eco Certification\n",
    "    if row['Eco_Certification'] != 'None':\n",
    "        labels.append('Certified Eco-Friendly')\n",
    "    \n",
    "    return ', '.join(labels)\n",
    "\n",
    "df['Sustainability_Label'] = df.apply(label_products, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d8c9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishgaikwad/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/Users/anishgaikwad/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Load datasets\n",
    "Final_data = pd.read_csv('Final_data.csv')\n",
    "User_data = pd.read_csv('User_data.csv')\n",
    "\n",
    "# Generate an empty interaction matrix\n",
    "interaction_matrix = pd.DataFrame(np.zeros((len(User_data), len(Final_data))), columns=Final_data['Product_ID'], index=User_data['User_ID'])\n",
    "\n",
    "# Fill interaction matrix based on matched preferences\n",
    "for user_idx, user_row in User_data.iterrows():\n",
    "    for product_idx, product_row in Final_data.iterrows():\n",
    "        score = 0\n",
    "        if user_row['Recyclable'] and product_row['Recyclable'] == 'Yes':\n",
    "            score += 1\n",
    "        if user_row['Energy Efficient'] and product_row['Eco_Certification'] in ['ENERGY STAR', 'Low VOC']:  # Assuming these certifications are related to energy efficiency\n",
    "            score += 1\n",
    "        if user_row['Water Efficient'] and 'Water Efficient' in product_row['Sustainability_Label']:\n",
    "            score += 1\n",
    "        if user_row['Certified Eco-Friendly'] and 'Certified Eco-Friendly' in product_row['Sustainability_Label']:\n",
    "            score += 1\n",
    "        interaction_matrix.at[user_row['User_ID'], product_row['Product_ID']] = score\n",
    "\n",
    "# Apply matrix factorization using NMF\n",
    "nmf = NMF(n_components=3)\n",
    "user_matrix = nmf.fit_transform(interaction_matrix)\n",
    "product_matrix = nmf.components_.T\n",
    "\n",
    "# If you need the resultant matrices saved as CSV\n",
    "pd.DataFrame(user_matrix, index=User_data['User_ID']).to_csv('user_matrix.csv')\n",
    "pd.DataFrame(product_matrix, index=Final_data['Product_ID']).to_csv('product_matrix.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12717d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_for_all_users(user_matrix, product_matrix, product_data, top_n=5):\n",
    "    all_recommendations = []\n",
    "\n",
    "    # Loop through each user\n",
    "    for user_id in range(user_matrix.shape[0]):\n",
    "        # Get the latent features for the user\n",
    "        user_vector = user_matrix[user_id]\n",
    "        \n",
    "        # Calculate the score for every product\n",
    "        scores = np.dot(user_vector, product_matrix.T)\n",
    "        \n",
    "        # Get the indices of the products sorted by descending scores\n",
    "        sorted_product_indices = scores.argsort()[::-1]\n",
    "        \n",
    "        # Pick the top_n product indices\n",
    "        top_product_indices = sorted_product_indices[:top_n]\n",
    "        \n",
    "        # Get the top product names\n",
    "        top_product_names = product_data.iloc[top_product_indices]['Product_Name'].values\n",
    "        \n",
    "        # Append the recommendations to the all_recommendations list\n",
    "        all_recommendations.append([user_id + 1] + list(top_product_names))  # Assuming User_ID starts from 1\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "# Load the latent feature matrices from CSV (if saved)\n",
    "user_matrix = pd.read_csv('user_matrix.csv', index_col=0).values\n",
    "product_matrix = pd.read_csv('product_matrix.csv', index_col=0).values\n",
    "\n",
    "# Get recommendations for all users\n",
    "all_user_recommendations = recommend_products_for_all_users(user_matrix, product_matrix, Final_data)\n",
    "\n",
    "# Convert recommendations to DataFrame and save to CSV\n",
    "recommendations_df = pd.DataFrame(all_user_recommendations, columns=['User_ID', 'Rec_Product_1', 'Rec_Product_2', 'Rec_Product_3', 'Rec_Product_4', 'Rec_Product_5'])\n",
    "recommendations_df.to_csv('user_recommendations1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "879346ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_for_all_users(user_matrix, product_matrix, product_data, top_n=5):\n",
    "    all_recommendations = []\n",
    "\n",
    "    # Loop through each user\n",
    "    for user_id in range(user_matrix.shape[0]):\n",
    "        # Get the latent features for the user\n",
    "        user_vector = user_matrix[user_id]\n",
    "        \n",
    "        # Calculate the score for every product\n",
    "        scores = np.dot(user_vector, product_matrix.T)\n",
    "        \n",
    "        # Get the indices of the products sorted by descending scores\n",
    "        sorted_product_indices = scores.argsort()[::-1]\n",
    "        \n",
    "        # Pick the top_n product indices\n",
    "        top_product_indices = sorted_product_indices[:top_n]\n",
    "        \n",
    "        # Get the top product names\n",
    "        top_product_names = product_data.iloc[top_product_indices]['Product_Name'].values\n",
    "        \n",
    "        # Create a concatenated string of recommended product names\n",
    "        recommended_products_str = ', '.join(top_product_names)\n",
    "        \n",
    "        # Append the recommendations to the all_recommendations list\n",
    "        all_recommendations.append([user_id + 1, recommended_products_str])  # Assuming User_ID starts from 1\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "# Load the latent feature matrices from CSV (if saved)\n",
    "user_matrix = pd.read_csv('user_matrix.csv', index_col=0).values\n",
    "product_matrix = pd.read_csv('product_matrix.csv', index_col=0).values\n",
    "\n",
    "# Get recommendations for all users\n",
    "all_user_recommendations = recommend_products_for_all_users(user_matrix, product_matrix, Final_data)\n",
    "\n",
    "# Convert recommendations to DataFrame and save to CSV\n",
    "recommendations_df = pd.DataFrame(all_user_recommendations, columns=['User_ID', 'Recommended_Products'])\n",
    "recommendations_df.to_csv('user_recommendations2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18b0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
